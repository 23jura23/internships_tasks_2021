{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SAMPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBits=1024\n",
    "depth=3\n",
    "\n",
    "# convertation smiles to morgan fingerprints bit vectors\n",
    "# (probably not the most pythonic way to do this :)\n",
    "mols = data['smiles'].apply(Chem.MolFromSmiles)\n",
    "fps_array = np.zeros((len(mols), nBits))\n",
    "for i in range(len(mols)):\n",
    "    mol = mols[i]\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(mol, depth, nBits=nBits)\n",
    "    fp_array = np.zeros((0,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, fp_array)\n",
    "    fps_array[i]= fp_array\n",
    "fps_array = np.array(fps_array)\n",
    "fps = pd.DataFrame(fps_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) filter the features to use only the frequent ones\n",
    "good_indices = []\n",
    "bound = 15\n",
    "for i in fps:\n",
    "    if sum(fps[i]) >= bound:\n",
    "        good_indices.append(i)\n",
    "fps_good = fps[good_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to train and test\n",
    "X_train, X_test, Y_train, Y_test, Calc_train, Calc_test = train_test_split(fps_good, data['expt'], data['calc'], test_size=0.2, random_state=1337, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=4, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=700, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train gradient boosting regressor\n",
    "GBR = ensemble.GradientBoostingRegressor(n_estimators=700, max_depth=4, min_samples_split=5)\n",
    "GBR.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train linear regressor\n",
    "Linear = LinearRegression()\n",
    "Linear.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(1024, 1024, 1024), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train multilayer perceptron\n",
    "MLP = MLPRegressor(hidden_layer_sizes=tuple([nBits]*depth), activation='relu')\n",
    "MLP.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR:\n",
      "MSE:       3.98812633679\n",
      "R^2 score: 0.765100377933\n",
      "Linear:\n",
      "MSE:       6.44636562047\n",
      "R^2 score: 0.62031071233\n",
      "MLP:\n",
      "MSE:       3.58151090824\n",
      "R^2 score: 0.789049922764\n",
      "Calc:\n",
      "MSE:       3.00768906202\n",
      "R^2 score: 0.822847882865\n"
     ]
    }
   ],
   "source": [
    "# Calculate errors of each regressor\n",
    "Y_pred = GBR.predict(X_test)\n",
    "print('GBR:')\n",
    "print('MSE:       {}'.format(mean_squared_error(Y_test, Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(Y_test, Y_pred)))\n",
    "Y_pred = Linear.predict(X_test)\n",
    "print('Linear:')\n",
    "print('MSE:       {}'.format(mean_squared_error(Y_test, Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(Y_test, Y_pred)))\n",
    "Y_pred = MLP.predict(X_test)\n",
    "print('MLP:')\n",
    "print('MSE:       {}'.format(mean_squared_error(Y_test, Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(Y_test, Y_pred)))\n",
    "# Calculate error of method from data (calc column)\n",
    "print('Calc:')\n",
    "print('MSE:       {}'.format(mean_squared_error(Y_test, Calc_test)))\n",
    "print('R^2 score: {}'.format(r2_score(Y_test, Calc_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR:\n",
      "MSE:       0.989074183411\n",
      "R^2 score: 0.933092262718\n",
      "Linear:\n",
      "MSE:       3.36142072408\n",
      "R^2 score: 0.772610529651\n",
      "MLP:\n",
      "MSE:       0.770395275175\n",
      "R^2 score: 0.947885198563\n",
      "Calc:\n",
      "MSE:       2.37627506075\n",
      "R^2 score: 0.839252514987\n"
     ]
    }
   ],
   "source": [
    "# All data\n",
    "Y_pred = GBR.predict(fps_good)\n",
    "print('GBR:')\n",
    "print('MSE:       {}'.format(mean_squared_error(data['expt'], Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(data['expt'], Y_pred)))\n",
    "Y_pred = Linear.predict(fps_good)\n",
    "print('Linear:')\n",
    "print('MSE:       {}'.format(mean_squared_error(data['expt'], Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(data['expt'], Y_pred)))\n",
    "Y_pred = MLP.predict(fps_good)\n",
    "print('MLP:')\n",
    "print('MSE:       {}'.format(mean_squared_error(data['expt'], Y_pred)))\n",
    "print('R^2 score: {}'.format(r2_score(data['expt'], Y_pred)))\n",
    "print('Calc:')\n",
    "print('MSE:       {}'.format(mean_squared_error(data['expt'], data['calc'])))\n",
    "print('R^2 score: {}'.format(r2_score(data['expt'], data['calc'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I decided to try different models for baseline: Gradient Boost Regressor, Linear Regressor and Multilayer Perceptron\n",
    "# All from the sklearn package\n",
    "# Linear regressor is not doing well, i.e. it shows bad mse and r2 score comparing to gbr and mlp\n",
    "# GBR and MLP show good results, and MLP dominate GBR a little, so I choose it as a baseline.\n",
    "\n",
    "# I also noticed that not-shuffled the data when splitting leads to, as I think, overfitting of models so they give scores better than calc\n",
    "# (i.e. I achieved about 0.87 r2 for GBX against 0.82 by calc, but this configuration is not presented above)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheminf-env",
   "language": "python",
   "name": "cheminf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
